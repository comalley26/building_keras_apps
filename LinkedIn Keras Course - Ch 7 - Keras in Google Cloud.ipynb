{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Keras Models in Tensorflow\n",
    "\n",
    "Since we are using a Tensorflow backend for Keras, we can export a Tensorflow model and upload to Google Cloud ML Service\n",
    "\n",
    "This will allow us to serve as many users as we need\n",
    "\n",
    "To do this, we need to add some code to our previous model building process\n",
    "\n",
    "Once process is finished, new folder (exported_mod) should contain variables and a model in .pb format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(\"sales_training_data_scaled.csv\")\n",
    "\n",
    "X = training_df.drop('total_earnings', axis = 1)\n",
    "y = training_df['total_earnings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 18:36:32.558413 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 18:36:32.603895 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 18:36:32.611962 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 18:36:32.768714 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0829 18:36:37.004478 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0829 18:36:37.309292 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "W0829 18:36:37.826806 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0829 18:36:37.828800 20452 deprecation_wrapper.py:119] From C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 0.0169\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.0032\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.0015\n",
      "Epoch 4/50\n",
      " - 0s - loss: 9.1098e-04\n",
      "Epoch 5/50\n",
      " - 0s - loss: 5.1822e-04\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3.0205e-04\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2.0601e-04\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1.6240e-04\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1.1810e-04\n",
      "Epoch 10/50\n",
      " - 0s - loss: 9.6540e-05\n",
      "Epoch 11/50\n",
      " - 0s - loss: 8.9356e-05\n",
      "Epoch 12/50\n",
      " - 0s - loss: 6.7844e-05\n",
      "Epoch 13/50\n",
      " - 0s - loss: 5.6235e-05\n",
      "Epoch 14/50\n",
      " - 0s - loss: 5.2814e-05\n",
      "Epoch 15/50\n",
      " - 0s - loss: 4.6795e-05\n",
      "Epoch 16/50\n",
      " - 0s - loss: 4.5136e-05\n",
      "Epoch 17/50\n",
      " - 0s - loss: 4.0333e-05\n",
      "Epoch 18/50\n",
      " - 0s - loss: 3.5412e-05\n",
      "Epoch 19/50\n",
      " - 0s - loss: 3.2808e-05\n",
      "Epoch 20/50\n",
      " - 0s - loss: 3.0273e-05\n",
      "Epoch 21/50\n",
      " - 0s - loss: 3.1052e-05\n",
      "Epoch 22/50\n",
      " - 0s - loss: 3.0211e-05\n",
      "Epoch 23/50\n",
      " - 0s - loss: 2.9904e-05\n",
      "Epoch 24/50\n",
      " - 0s - loss: 3.4065e-05\n",
      "Epoch 25/50\n",
      " - 0s - loss: 3.1824e-05\n",
      "Epoch 26/50\n",
      " - 0s - loss: 2.7960e-05\n",
      "Epoch 27/50\n",
      " - 0s - loss: 3.0442e-05\n",
      "Epoch 28/50\n",
      " - 0s - loss: 3.1730e-05\n",
      "Epoch 29/50\n",
      " - 0s - loss: 2.6843e-05\n",
      "Epoch 30/50\n",
      " - 0s - loss: 4.4470e-05\n",
      "Epoch 31/50\n",
      " - 0s - loss: 2.6844e-05\n",
      "Epoch 32/50\n",
      " - 0s - loss: 3.1589e-05\n",
      "Epoch 33/50\n",
      " - 0s - loss: 2.6023e-05\n",
      "Epoch 34/50\n",
      " - 0s - loss: 2.8962e-05\n",
      "Epoch 35/50\n",
      " - 0s - loss: 3.0845e-05\n",
      "Epoch 36/50\n",
      " - 0s - loss: 2.8517e-05\n",
      "Epoch 37/50\n",
      " - 0s - loss: 2.7220e-05\n",
      "Epoch 38/50\n",
      " - 0s - loss: 2.2650e-05\n",
      "Epoch 39/50\n",
      " - 0s - loss: 2.8800e-05\n",
      "Epoch 40/50\n",
      " - 0s - loss: 2.4351e-05\n",
      "Epoch 41/50\n",
      " - 0s - loss: 2.3310e-05\n",
      "Epoch 42/50\n",
      " - 0s - loss: 2.2670e-05\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1.8068e-05\n",
      "Epoch 44/50\n",
      " - 0s - loss: 2.8098e-05\n",
      "Epoch 45/50\n",
      " - 0s - loss: 3.3285e-05\n",
      "Epoch 46/50\n",
      " - 0s - loss: 2.3751e-05\n",
      "Epoch 47/50\n",
      " - 0s - loss: 2.9072e-05\n",
      "Epoch 48/50\n",
      " - 0s - loss: 4.1001e-05\n",
      "Epoch 49/50\n",
      " - 0s - loss: 4.4135e-05\n",
      "Epoch 50/50\n",
      " - 0s - loss: 2.2796e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2155708f588>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerun model as we did last chapter\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_dim = 9, activation='relu', name = 'layer_1'))\n",
    "model.add(Dense(100, activation='relu', name = 'layer_2'))\n",
    "model.add(Dense(50, activation='relu', name = 'layer_3'))\n",
    "model.add(Dense(1, activation='linear', name = 'output_layer'))\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "logger = keras.callbacks.TensorBoard(log_dir='logs', write_graph=True)\n",
    "\n",
    "model.fit(X, y, epochs = 50, shuffle = True, verbose = 2, callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) for the test data set is: 3.361954042338766e-05\n"
     ]
    }
   ],
   "source": [
    "# test results\n",
    "\n",
    "test_data_df = pd.read_csv(\"sales_testing_data_scaled.csv\")\n",
    "\n",
    "X_test = test_data_df.drop('total_earnings', axis=1)\n",
    "Y_test = test_data_df['total_earnings']\n",
    "\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: exported_model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f855231e5ec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# first we need to create a saved model builder object - only argument is name of folder where u want to save it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel_builder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"exported_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\builder_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, export_dir)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_add_collections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massets_collection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\builder_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, export_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;34m\"Export directory already exists, and isn't empty. Please choose \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;34m\"a different export directory, or delete all the contents of the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \"specified directory: %s\" % export_dir)\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_export_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: exported_model"
     ]
    }
   ],
   "source": [
    "# to export model as a TF model, we need to use TF-specific code\n",
    "\n",
    "# first we need to create a saved model builder object - only argument is name of folder where u want to save it\n",
    "\n",
    "model_builder = tf.saved_model.builder.SavedModelBuilder(\"exported_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to tell TF which specific inputs and outputs we want to use when making predictions\n",
    "\n",
    "# we pass in the input and output methods from the Keras model we built above\n",
    "\n",
    "inputs = {'input':tf.compat.v1.saved_model.build_tensor_info(model.input)}\n",
    "\n",
    "outputs = {'earnings':tf.compat.v1.saved_model.build_tensor_info(model.output)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to create a TF signature def to tell TF how to run prediction function of the model\n",
    "\n",
    "# this code will be the same every time\n",
    "\n",
    "signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "    inputs = inputs,\n",
    "    outputs = outputs,\n",
    "    method_name = tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also add a meta graph and variables to save structure and trained weights of the model\n",
    "\n",
    "# we pass in a reference to current keras session, then add tags so Tensorflow knows this model is for serving users\n",
    "\n",
    "# then we pass in signature def created above and save it\n",
    "\n",
    "model_builder.add_meta_graph_and_variables(\n",
    "    K.get_session(),\n",
    "    tags = [tf.saved_model.tag_constants.SERVING],\n",
    "    signature_def_map = {tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:signature_def}\n",
    ")\n",
    "\n",
    "model_builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google Cloud\n",
    "\n",
    "We can use a Gmail account to sign into the Google Cloud platform\n",
    "\n",
    "Once we get there, we need to create a new project where we will run the model\n",
    "\n",
    "With the new project selected at the top, we need to enable ML service under APIs & Services -> Library -> Cloud Machine Learning Engine\n",
    "\n",
    "Note the Google will only charge per request on the model so servers are only used as needed\n",
    "\n",
    "We then had to download the Google SDK and sign into Gmail account\n",
    "\n",
    "There are two things we need to do to upload the model to the cloud:\n",
    "\n",
    "1. Upload model files to Google Cloud storage bucket\n",
    "2. Create new Google ML model using uploaded files\n",
    "\n",
    "Once in the cloud, we can test the model on the sample input prescaled data from the lecture files (in JSON format)\n",
    "\n",
    "We do this by opening regular command prompt and creating a unique storage bucket in the right folder directory with:\n",
    "\n",
    "gsutil mb -l us-central1 gs://keras-class-052694\n",
    "\n",
    "We then enter the following code to move the model to the storage bucket as earnings_v1:\n",
    "\n",
    "gsutil cp -R exported_model/* gs://keras-class-052694/earnings_v1\n",
    "\n",
    "Now that model files are on Google servers, we need to tell ML engine to create a new model:\n",
    "\n",
    "gcloud ai-platform models create earnings_model --regions us-central1\n",
    "\n",
    "Since we can make multiple models, we need to create the first version of the model:\n",
    "\n",
    "gcloud ai-platform versions create v1 --model=earnings_model --origin=gs://keras-class-052694/earnings_v1 --runtime-version=1.2\n",
    "\n",
    "Now we can predict values with this model (NOT WORKING - ERROR SHOWS UP AFTER THIS RUNS):\n",
    "\n",
    "gcloud ai-platform predict --model=earnings --json-instances=sample_input_prescaled.json\n",
    "\n",
    "# Using Google APIs\n",
    "\n",
    "We can use a variety of languages to pull data from Google APIs\n",
    "\n",
    "To use a cloud based ML model from another program, we need two things:\n",
    "\n",
    "1. Permission to make calls to the cloud (credentials file)\n",
    "2. Write code to call cloud based model\n",
    "\n",
    "To make credentials, you need to go to console.cloud.google.com -> API Manager -> Credentials -> Create Service Account Key\n",
    "\n",
    "Then you need to make an account name and select Project -> Viewer role\n",
    "\n",
    "Once you click create, move the downloaded json file to the folder you are working in\n",
    "\n",
    "Code below from lecture shows how to connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Change this values to match your project\n",
    "PROJECT_ID = \"keras-class-052694\"\n",
    "MODEL_NAME = \"earnings_model_1\"\n",
    "CREDENTIALS_FILE = \"credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the values we want a prediction for\n",
    "inputs_for_prediction = [\n",
    "    {\"input\": [0.4999, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 18:38:01.782690 20452 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\googleapiclient\\discovery_cache\\__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ModuleNotFoundError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\googleapiclient\\discovery_cache\\__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"C:\\Users\\casey\\Anaconda3\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Google Cloud-ML Service\n",
    "\n",
    "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
    "service = googleapiclient.discovery.build('ml', 'v1', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 18:39:59.126796 20452 http.py:118] Invalid JSON content from response: b'{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"Permission denied on resource project keras-class-052694.\",\\n    \"status\": \"PERMISSION_DENIED\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.Help\",\\n        \"links\": [\\n          {\\n            \"description\": \"Google developer console API key\",\\n            \"url\": \"https://console.developers.google.com/project/keras-class-052694/apiui/credential\"\\n          }\\n        ]\\n      }\\n    ]\\n  }\\n}\\n'\n"
     ]
    },
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://ml.googleapis.com/v1/projects/keras-class-052694/models/earnings_model_1:predict?alt=json returned \"Permission denied on resource project keras-class-052694.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Google developer console API key', 'url': 'https://console.developers.google.com/project/keras-class-052694/apiui/credential'}]}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-35f8c07464b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'projects/{}/models/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'instances'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputs_for_prediction\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Report any errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\googleapiclient\\_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\googleapiclient\\http.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 403 when requesting https://ml.googleapis.com/v1/projects/keras-class-052694/models/earnings_model_1:predict?alt=json returned \"Permission denied on resource project keras-class-052694.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Google developer console API key', 'url': 'https://console.developers.google.com/project/keras-class-052694/apiui/credential'}]}]\">"
     ]
    }
   ],
   "source": [
    "# Connect to our Prediction Model\n",
    "\n",
    "name = 'projects/{}/models/{}'.format(PROJECT_ID, MODEL_NAME)\n",
    "\n",
    "response = service.projects().predict(name=name, body={'instances': inputs_for_prediction}).execute()\n",
    "\n",
    "# Report any errors\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "# Grab the results from the response object\n",
    "results = response['predictions']\n",
    "\n",
    "# Print the results!\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
